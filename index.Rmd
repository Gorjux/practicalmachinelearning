---
title: "Practical Machine Learning Course Project"
author: "Barbara Gorjux"
date: "27 mai 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### **INTRODUCTION:**
The goal of this project is to predict the manner in which the participants did the exercise. We use the dataset Weight Lifting Exercises (WLE). In this data set, the «classe» variable quatify "how well" the participants did the exercise. 

I will fit two models and choice one of then to make the prediction in the testing set.

URL and info about the data set:
 http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har)
This dataset collected by Velloso, E. ; Bulling, A. ; Gellersen, H. ; Ugulino, W. ; Fuks, H.. Thanks for their generosity.

#### **Loading library**
```{r}
library(lattice)
library(ggplot2)
library(caret)
library(randomForest)

```
### **DATA PREPARATION**
#### **Loading Data sets**
```{r}
destfile="pml-training.csv"
fileURL<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
if(!file.exists(destfile)){
  download.file(fileURL, destfile, method="auto")}

destfile="pml-testing.csv"
fileURL<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists(destfile)){
  download.file(fileURL, destfile, method="auto")}
```
#### **Reading the data sets**
```{r}
train<-read.csv(file = "pml-training.csv")
test<-read.csv(file = "pml-testing.csv")

```
#### **Cleaning the data**

* **First step**:I remove the variables which contain fast only NA's values 
```{r}
onlyNA<-sapply(train, function(x) mean(is.na(x)))>0.95
training<-train[, onlyNA==F]

```

* **Second step**:I remove the 7 first variables which don't measure how the participant performe the exercise
```{r}
training<-training[,-(1:7)]
```

* **Third step**:I remove the variables which have a near zero variability
```{r}
nzv<-nearZeroVar(training)
training<-training[,-nzv]
```

* **Fourth step**: I use PCA (principal component analysis) to choice the more relevant variables
```{r}
training.matrix<-data.matrix(training, rownames.force=NA) #convert the data frame into a matrix
dim(training.matrix)
pca<-prcomp(training.matrix, scale=TRUE) #calculate PCA
pca.var<-pca$sde^2 #variation of each component
pca.var.per<-round(pca.var/sum(pca.var)*100,3)#percentage of variation
pca.var.per 
sum(pca.var.per[1:40])#the first 40 components account for 99% of the variation
variable_score<-pca$rotation[,1]# load the rotation of each component
va_variable_score<-abs(variable_score)#take the absolute value
variable_score_ranked<-sort(va_variable_score, decreasing = TRUE)#rank the component
top_40_variables<-names(variable_score_ranked[1:40])#extract the names of the 40 best variables

training<-training[top_40_variables]
```
* **fifth step**: I cheak if 'classe' variable is allways in the data
```{r}
"classe"%in%names(training)
```
#### **Splitting the training data into a training and a testing data set**
```{r}
inTrain<-createDataPartition(y=training$classe, p=0.7, list=F)
training<-training[inTrain,]
testing<-training[-inTrain,]

```
#### **For reproductibility**
```{r}
set.seed(10)
```

### **FITTING TWO MODELS**

I first will use the trainControl()'s function in order to built a 3-fold cross validation. The cross-validation allows me to estimate the out of sample error. 

I have a classification and supervised learning problem. The goal is to predict the outcome "classe" with the inputs (the 39 variables I have selectided). "classe" is a qualitativ variable, which evaluate how well the exersise did (A correspond to correctly and B,C,D,E correspond to specific mistakes). Then I will built two models: random forest model and a boosted trees model. I use a preprocess in order to center and scale the variables.

#### **built a 3-fold cross validation**
```{r}
fitControl<-trainControl(method="cv",number=3, verboseIter = FALSE)

```

#### **First model: Random forest**
```{r}
fitRF<-train(classe~., data=training, method="rf", preProcess=c("center", "scale"), trControl=fitControl)
```

#### **Second model: Boosted trees**
```{r}
fitGBM<-train(classe~., data=training, method="gbm",preProcess=c("center", "scale"), trControl=fitControl, verbose=FALSE)

```

### **COMPARING THE MODELS** 
####* **first step**: informations on the models
```{r}
print(fitRF)
print(fitGBM)
#Looking the values of the accuracies and the kappas, random forest seems to be a better model than boosted trees.
```
####* **Second step**:CALCULATE the OUT OF SAMPLE ERROR
```{r}
errorRF<-1-mean(fitRF$resample$Accuracy)
errorGBM<-1-mean(fitGBM$resample$Accuracy)
errorRF
errorGBM
#The out of sample error is smaller for the random forest model as for the boosted trees. I choice the random forest model.
```

### **PREDICTION WITH TRAINING**
```{r}
predTRAINING<-predict(fitRF, training)
confusionMatrix(training$classe, predTRAINING)
```

### **PREDICTION WITH TESTING**
```{r}
predTRAINING<-predict(fitRF, testing)
confusionMatrix(testing$classe, predTRAINING)

```



